<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>javidibaghban</title>
<meta name="description" content="I worked on pattern recognition" />
</head>

<body style="background-color:#3CF;">
<table border="1" width="980" height="800" style="margin-left:auto;margin-right:auto;background-image:url(Abstract_Shining_Background_02.jpg);">
	<tr>
		<td colspan="3" height="100">
			<h1 style="text-align:center;">
				article....
			</h1>
		</td>	
	</tr>
	<tr>
		<td width="120" style="vertical-align:top;"><br />
			<ul>
				<li><a href="index.html">home</a></li>
				<li><a href="contact.html">contact</a></li>
				<li><a href="about.html">about</a></li>
				<li><a href="article.html">article</a></li>
			</ul>
		</td>
		<td>
			<p style="font-size:24px;">
				The nearest sub-class classifier-a compromise between the nearest mean and nearest neighbor classifier :<br />
			</p>
			<p> 
				Abstract We present the Nearest Sub-class Classifier (NSC), which is a classification algorithm
that unifies the fiexibility of the nearest neighbor classifier with the robustness of the nearest mean
classifier. The algorithm is based on the Maximum Variance Cluster algorithm and as such it belongs
to the class of prototype-based classifiers. The variance constraint parameter of the cluster algorithm
serves to regularise the classifier, that is, to prevent overfitting. With a low variance constraint value
the classifier turns into the nearest neighbor classifier and with a high variance parameter it becomes
the nearest mean classifier with the respective properties. In other words, the number of prototypes
ranges from the whole training set to only one per class. In the experiments, we compared the NSC
with regard to its performance and data set compression ratio to several other prototype-based methods.
On several data sets the NSC performed similarly to the k-nearest neighbor classifier, which is
a well-established classifier in many domains. Also concerning storage requirements and classification
speed, the NSC has favorable properties, so it gives a good compromise between classification
performance and efficiency.	
			</p>
		</td>
		<td width="120"></td>	
	</tr>
	<tr>
		<td colspan="3" height="80">
			Thanks for your attention.....
		</td>
		
			
	</tr>
</table>
</body>
</html>
